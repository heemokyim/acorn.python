{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN\n",
    "1) Recurrent Neural Network - 시간의 흐름을 반영\n",
    "* 순차적인 흐름이 중요할 때\n",
    "2) Recursive Neural Network - 순환\n",
    "\n",
    "1. 일반 신경망이론\n",
    "- FNN : 순방향신경망\n",
    "\n",
    "ex)                hidden\n",
    "H e l l o [Xo] --> [∑,f] --> [∑,f] --> y (softmax(label 3이상일때),loss(최적의 w값))\n",
    "* sequence number -> 한번에 몇개를 보느냐 : 즉, hidden layer의 갯수를 의미함.\n",
    "* 인공신경망과의 차이점: 하나의 층에서 나온 값이 다음의 층에 영향을 줘서 결정에 영향을 준다.\n",
    "* hidden layer안에 노드의 수 : 비선형적으로 볼 수 있다.\n",
    "* \"어렴풋이\" 과거의 데이터에 대한 정보를 기억할 수 있는 기능이 있다고 여김.(정확하게가 아님)\n",
    "\n",
    "## RNN 사용\n",
    "1. 시간의 흐름이 있는 데이터\n",
    "2. 순차적인 언어,동영상의 경우\n",
    "\n",
    "## RNN의 weight 종류\n",
    "1. Whh - 층에서 다음층으로 가는 가중치\n",
    "2. Wxh - 입력에서 히든레이어로 가는 가중치\n",
    "3. Why - 히든레이어에서 출력으로 가는 가중치\n",
    "\n",
    "ht( 히든레이어) tanh(Whh*ht-1 + Wxh*Xt(입력값)+bh) - 히든레이어에서 쓰이는 판별함수:탄젠트하이퍼\n",
    "yt = Why*ht + by\n",
    "\n",
    "* 시간의 순으로 펼쳐서 보는 것 - unfolding\n",
    "* sequence number의 갯수로 한번에 보는 것들은 세 개의 가중치가 다 같은 값을 가지게 된다.\n",
    "ex) 3개씩 보겠다 (sequence number)\n",
    "- 각 세개의 가중치(Whh, Wxh, Why)가 각각 같아진다.\n",
    "\n",
    "## LSTM\n",
    "1. RNN의 vanishing 문제 해결\n",
    "- weight 값이 너무 작아지거나 커지거나(곱하기의 연산이 많기때문에)\n",
    "==> 해결: 제어정보를 통해 최소한의 곱연산만 남기고 나머지는 덧셈연산\n",
    "==> 해결: forget gate를 추가해서 오차가 큰 값들을 제거한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
